is3d: true
checkpoints:
  continue_training: false # continue training from a checkpoint (use it with ckpt_path)
  test_mode: true # test mode (use it with ckpt_path)
  ckpt_path: '/home/say26747/Desktop/lhUNET_SGD_DEV_dr0.1_V7_lr0.003_kernel_3_dec_5_test_as_val-epoch=963-val_total_dice=0.860515.ckpt'
  save_nifty: true # save nifty files
dataset:
  name: "brats2018_loader"
  input_size: [128,128,128]
  train:
    params:
      data_root: "/home/say26747/Desktop/datasets/Brats 2018"
      # data_root: "$TMPDIR/MICCAI_BraTS_2018_Data_Training"
      # data_root: "/cabinet/dataset/brats/Brats 2018"
      normalization: true
      augmentation: true  
      p: 0.5

  validation:
    params:
      data_root: "/home/say26747/Desktop/datasets/Brats 2018"
      # data_root: "$TMPDIR/MICCAI_BraTS_2018_Data_Training"
      # data_root: "/cabinet/dataset/brats/Brats 2018"
      normalization: true
      augmentation: false  

  test:
    params:
      data_root: "/home/say26747/Desktop/datasets/Brats 2018"
      # data_root: "$TMPDIR/MICCAI_BraTS_2018_Data_Training"
      # data_root: "/cabinet/dataset/brats/Brats 2018"
      normalization: true
      augmentation: false 

  test_split: 0.2
  validation_split: 0.1
data_loader:
  train: 
    batch_size: 2
    shuffle: true
    num_workers: 12
    pin_memory: true
    persistent_workers: true
  validation: 
    batch_size: 1
    shuffle: false
    num_workers: 12
    pin_memory: true
    persistent_workers: true
  test:
    batch_size: 1
    shuffle: false
    num_workers: 12
    pin_memory: false
    persistent_workers: true
training:
  optimizer:
    name: 'SGD'
    params:
      lr: 0.01
      momentum: 0.99
      weight_decay : 0.00003
      nesterov: true
  criterion:
    params: 
      dice_weight: 0.5
      bce_weight: 0.5
  scheduler:
    name: 'CustomDecayLR'
    params:
      max_epochs: 1000
  epochs: 1000
  
model: 
  name: 'lhUNET_SGD_DEV_test' # do not change the lhUNET name at the begining
  params:
    spatial_shapes: [128,128,128]
    do_ds: false # Deep Supervision
    in_channels: 4
    out_channels: 4
        
     # encoder params
    cnn_kernel_sizes: [3,3]
    cnn_features: [12,16]
    cnn_strides: [2,2]
    cnn_maxpools: [true, true]
    cnn_dropouts: 0.0
    cnn_blocks: nn # n: resunet, d: deformconv, b: basicunet
    hyb_kernel_sizes: [3,3,3]
    hyb_features: [32,64,128]
    hyb_strides: [2,2,2]
    hyb_maxpools: [true,true,true]
    hyb_cnn_dropouts: 0.0
    hyb_tf_proj_sizes: [64,32,0]
    hyb_tf_repeats: [1,1,1]
    hyb_tf_num_heads: [4,4,8]
    hyb_tf_dropouts: 0.1
    hyb_cnn_blocks: nnn # n: resunet, d: deformconv, b: basicunet
    hyb_vit_blocks: SSC # s: dlka_special_v2, S: dlka_sp_seq, c: dlka_channel_v2, C: dlka_ch_seq
    # hyb_vit_sandwich: false
    hyb_skip_mode: "cat" # "sum" or "cat"
    hyb_arch_mode: "residual" # sequential, residual, parallel, collective
    hyb_res_mode: "sum" # "sum" or "cat"
                
    # decoder params
    dec_hyb_tcv_kernel_sizes: [5,5,5]
    dec_cnn_tcv_kernel_sizes: [5,5]
    dec_cnn_blocks: null
    dec_tcv_bias: false
    dec_hyb_tcv_bias: false
    dec_hyb_kernel_sizes: null
    dec_hyb_features: null
    dec_hyb_cnn_dropouts: null
    dec_hyb_tf_proj_sizes: null
    dec_hyb_tf_repeats: null
    dec_hyb_tf_num_heads: null
    dec_hyb_tf_dropouts: null
    dec_cnn_kernel_sizes: null
    dec_cnn_features: null
    dec_cnn_dropouts: null
    dec_hyb_cnn_blocks: null
    dec_hyb_vit_blocks: null
    # dec_hyb_vit_sandwich: null
    dec_hyb_skip_mode: null
    dec_hyb_arch_mode: "collective" # sequential, residual, parallel, collective, sequential-lite
    dec_hyb_res_mode: null

use_sliding_window: true
sliding_window_params:
  overlap: 0.5
  mode: 'gaussian'